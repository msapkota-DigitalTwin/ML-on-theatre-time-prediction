{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615a3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8c77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_direc = 'Z:\\Capacity & Analytics\\Business Informatics\\Analytics Team\\Surgical Elective Patient Scheduling Model\\Theatre_Procedure_Time_Predictive_Modelling\\Data_and_model_Nov_2024'\n",
    "os.chdir(work_direc)\n",
    "#df = pd.read_excel('InPatient_data_T_O_June_Aug2023.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea944d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Session Planned End Date/Time', 'Planned Start Date/Time',\n",
       "       'Planned Duration', 'Arrived Date/Time', 'Into Theatre Date/Time',\n",
       "       'Out of Theatre Date/Time', 'Actual Procedure 1 Code 1',\n",
       "       'Actual Duration', 'H4 Minutes',\n",
       "       'First Knife to Skin to Last Knife Down Minutes', 'Consultant',\n",
       "       'Consultant Code', 'Operating Surgeon', 'Specialty', 'Theatre Name',\n",
       "       'Theatre Suite Name', 'Patient Classification',\n",
       "       'anaesthetist 1 Surname, Forename', 'anaesthetist 1 Role',\n",
       "       'anaesthetist 2 Surname, Forename', 'anaesthetist 2 Role',\n",
       "       'anaesthetist 3 Surname, Forename', 'anaesthetist 3 Role',\n",
       "       'anaesthetist 4 Surname, Forename', 'anaesthetist 4 Role',\n",
       "       'anaesthetist Expected?', 'Actual Procedure 1 Code 1.1',\n",
       "       'Actual Procedure 1 Description 1', 'Actual Procedure 1 Code 2',\n",
       "       'Actual Procedure 1 Description 2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Theatre_raw_SQL_data_TO_col_2018_2024.xlsx')\n",
    "df.columns[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fd17fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing_nd_encoding_related_functions import age_to_group\n",
    "\n",
    "def data_prep_first_step_after_SQl_extraction(input_file_name, output_file_name):\n",
    "    \n",
    "    def add_count_column(df1, columns_to_count, new_col):\n",
    "        # Calculate the count of non-missing and non-zero values for each row\n",
    "        df1[new_col] = df1[columns_to_count].apply(lambda row: (row != 0) & (pd.notna(row))).sum(axis=1)\n",
    "\n",
    "    def categorise_covid_period(date):\n",
    "        if date < pd.Timestamp('2020-03-01'):\n",
    "            return 'pre-covid'\n",
    "        elif date >= pd.Timestamp('2020-03-01') and date <= pd.Timestamp('2021-03-30'):\n",
    "            return 'covid'\n",
    "        else:\n",
    "            return 'post-covid'\n",
    "    \n",
    "    # Check the file extension and read the file accordingly\n",
    "    if input_file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(input_file_name)\n",
    "        print(f\"DataFrame loaded from CSV: {input_file_name}\")\n",
    "    elif input_file_name.endswith('.xlsx'):\n",
    "        df = pd.read_excel(input_file_name, engine='openpyxl')  # Use openpyxl for .xlsx files\n",
    "        print(f\"DataFrame loaded from Excel file: {input_file_name}\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use a .csv or .xlsx file.\")\n",
    "\n",
    "    \n",
    "    df = df.replace(['Unknown', '^Not Stated', 'Not Known'], np.nan, regex=True)\n",
    "\n",
    "    add_count_column(df, ['Actual Procedure 1 Code 1','Actual Procedure 2 Code 1','Actual Procedure 3 Code 1'], 'N_procedures')\n",
    "\n",
    "    anaesthetic_cols = ['anaesthetist 1 Surname, Forename',\n",
    "                      'anaesthetist 2 Surname, Forename',\n",
    "                      'anaesthetist 3 Surname, Forename']\n",
    "\n",
    "    add_count_column(df, anaesthetic_cols, 'Anaesthetist Count')\n",
    "\n",
    "    df = df.replace({'ETHNICITY': {'White - Any other White background' : 'Any other White background',\n",
    "                          'Any Other Ethnic Group': 'Any other ethnic group',\n",
    "                          'Black African or Black British African' : 'Black or Black British - African',\n",
    "                         'Any other Black background': 'Black or Black British - Any other Black background',\n",
    "                          'Black Caribbean or Black British Caribbean':'Black or Black British - Caribbean',\n",
    "                          'White - British': 'White British',\n",
    "                          'White - Irish' : 'White Irish',\n",
    "                          'Mixed - White and Asian':'Mixed White and Asian',\n",
    "                          'Mixed - White and Black Caribbean' : 'Mixed White and Black Caribbean',\n",
    "                          'Mixed - Any other background': 'Any other mixed background',\n",
    "                          'Mixed - White and Black African' : 'Mixed White and Black African',\n",
    "                          'Pakistani or British Pakistani': 'Asian or Asian British - Pakistani',\n",
    "                          'Other Ethnic Group - Chinese': 'Asian or Asian British - Chinese',\n",
    "                          'Chinese': 'Asian or Asian British - Chinese',\n",
    "                          'Bangladeshi or British Bangladeshi':'Asian or Asian British - Bangladeshi',\n",
    "                          'Asian - other' : 'Asian or Asian British - Any other Asian background',\n",
    "                          'Indian or British Indian':'Asian or Asian British - Indian'}})\n",
    "\n",
    "\n",
    "    white = ['White British', 'White Irish', 'Any other White background']\n",
    "    other_ethnic_group = ['Any other ethnic group',\n",
    "                          'Black or Black British - African',\n",
    "                          'Black or Black British - Any other Black background',\n",
    "                          'Black or Black British - Caribbean',\n",
    "                          'Mixed White and Asian',\n",
    "                          'Mixed White and Black Caribbean',\n",
    "                          'Any other mixed background',\n",
    "                          'Mixed White and Black African',\n",
    "                          'Asian or Asian British - Pakistani',\n",
    "                          'Asian or Asian British - Chinese',\n",
    "                          'Asian or Asian British - Chinese',\n",
    "                          'Asian or Asian British - Bangladeshi',\n",
    "                          'Asian or Asian British - Any other Asian background',\n",
    "                          'Any other Asian background',\n",
    "                          'Asian or Asian British - Indian']\n",
    "    \n",
    "    conditions = [df['ETHNICITY'].isin(white), df['ETHNICITY'].isin(other_ethnic_group),\n",
    "                  df['ETHNICITY'].isna()]\n",
    "    \n",
    "    categories = ['Any white background', 'Any other ethnic background', \"None\"]\n",
    "    \n",
    "    df['Ethnicity_grouped'] = np.select(conditions, categories)\n",
    "\n",
    "    Codes_for_conditions = {\n",
    "        'IHD': ['I200', 'I201', 'I208', 'I209', 'I210', 'I211', 'I212', 'I213', 'I214', 'I219', 'I220', 'I221', 'I228', 'I229', \n",
    "                'I230', 'I231', 'I232', 'I233', 'I234', 'I235', 'I236', 'I238', 'I240', 'I241', 'I248', 'I249', 'I250', 'I251', 'I252', 'I253', 'I254', 'I255', 'I256', 'I258', 'I259'],\n",
    "        'PAD': ['I7021', 'I7020', 'I7081', 'I7080', 'I7091', 'I7090', 'I72', 'I730', 'I731', 'I738', \n",
    "                'I739', 'I742', 'I743', 'I744', 'I745', 'I748', 'I749', 'I77', 'I792', 'I798'],\n",
    "        'Myocardial infraction': ['I21', 'I22', 'I23', 'I252', 'I258'],\n",
    "        'Cerebral vascular': ['G450', 'G451', 'G452', 'G454', 'G458', 'G459', 'G46', 'I60',\n",
    "                              'I61', 'I62', 'I63', 'I64', 'I65', 'I66', 'I67', 'I68', 'I69'],\n",
    "        'Congestive heart failure': ['I500'],\n",
    "        'Connective tissue disorder': ['M05', 'M060', 'M063', 'M069', 'M32', 'M332', 'M34', 'M353'],\n",
    "        'Dementia': ['F00', 'F01', 'F02', 'F03', 'F051'],\n",
    "        'Hypertension': ['I10', 'I11', 'I12', 'I13', 'I15', 'I16'],\n",
    "        'Diabetes': ['E101', 'E105', 'E106', 'E108', 'E109', 'E111', 'E115', 'E116', 'E118', 'E119', 'E131', 'E135', 'E136', 'E138', 'E139', 'E141', 'E145', 'E146', 'E148', 'E149'],\n",
    "        'Liver disease': ['K702', 'K703', 'K717', 'K73', 'K74'],\n",
    "        'Obesity': ['Z68', 'E66'],\n",
    "        'Peptic ulcer': ['K25', 'K26', 'K27', 'K28'],\n",
    "        'Periph vasc disease': ['I71', 'I739', 'I790', 'R02', 'Z958', 'Z959']\n",
    "    }\n",
    "\n",
    "    secondary_code_cols = df.columns[df.columns.str.startswith('Secondary_Diagnosis')][0:-1:2]\n",
    "\n",
    "    for key, string_list in Codes_for_conditions.items():\n",
    "        #print(string_list)\n",
    "        #default value is 0\n",
    "        diagnosis_result = np.zeros(len(df))\n",
    "        for index, row in df.iterrows():\n",
    "            for diag_code in row[secondary_code_cols]:  # Exclude the last column (NewColumn)\n",
    "                if pd.isna(diag_code):\n",
    "                    break\n",
    "                if any(s in diag_code for s in string_list):\n",
    "                    diagnosis_result[index]= 1\n",
    "                    break  # Stop checking if a string is found in any column\n",
    "        df[key] = diagnosis_result\n",
    "\n",
    "    df['Age group at admit'] = df['AGE_ON_ADMISSION'].apply(lambda x: age_to_group(x, [5, 15, 30, 50, 60, 70, 80]))\n",
    "\n",
    "    # Check and proceed line by line\n",
    "    if 'Arrived Date/Time' in df.columns:\n",
    "        df['Arrived Date/Time'] = pd.to_datetime(df['Arrived Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "    \n",
    "    if 'Out of Theatre Date/Time' in df.columns:\n",
    "        df['Out of Theatre Date/Time'] = pd.to_datetime(df['Out of Theatre Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "    \n",
    "    if 'Arrived Date/Time' in df.columns and 'Out of Theatre Date/Time' in df.columns and 'H4 Minutes' in df.columns:\n",
    "        df['Out of Theatre Date/Time'] = df.apply(\n",
    "            lambda row: row['Arrived Date/Time'] + pd.to_timedelta(row['H4 Minutes'], unit='minutes')\n",
    "            if pd.isnull(row['Out of Theatre Date/Time']) else row['Out of Theatre Date/Time'], \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    if 'Discharge Date/Time' in df.columns and 'Admission Date/Time' in df.columns:\n",
    "        df['Actual LOS'] = (\n",
    "            pd.to_datetime(df['Discharge Date/Time'], format=\"%d/%m/%Y %H:%M\") - \n",
    "            pd.to_datetime(df['Admission Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "        ).dt.total_seconds() / (24 * 3600)\n",
    "    \n",
    "    if 'Discharge Date/Time' in df.columns and 'Out of Theatre Date/Time' in df.columns:\n",
    "        df['Post-Op LOS'] = (\n",
    "            pd.to_datetime(df['Discharge Date/Time'], format=\"%d/%m/%Y %H:%M\") - \n",
    "            pd.to_datetime(df['Out of Theatre Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "        ).dt.total_seconds() / (24 * 3600)\n",
    "    \n",
    "    if 'Admission Date/Time' in df.columns:\n",
    "        df['Admission Date/Time'] = pd.to_datetime(df['Admission Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "        df['Month'] = df['Admission Date/Time'].apply(lambda x: x.strftime('%B'))\n",
    "        df['Covid Flag'] = df['Admission Date/Time'].apply(categorise_covid_period)\n",
    "    \n",
    "    if 'Planned Start Date/Time' in df.columns:\n",
    "        df['Day of the week'] = pd.to_datetime(df[\"Planned Start Date/Time\"], format=\"%d/%m/%Y %H:%M\").dt.day_name()\n",
    "\n",
    "    # Check the file extension and save accordingly\n",
    "    if output_file_name.endswith('.csv'):\n",
    "        df.to_csv(output_file_name, index=False)\n",
    "        print(f\"DataFrame saved as CSV: {output_file_name}\")\n",
    "    elif output_file_name.endswith('.xlsx'):\n",
    "        df.to_excel(output_file_name, index=False, engine='openpyxl')  # Use openpyxl for .xlsx files\n",
    "        print(f\"DataFrame saved as Excel file: {output_file_name}\")\n",
    "    else:\n",
    "        print(\"Unsupported file format. Please use a .csv or .xlsx file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45da0635-de23-4f45-81c0-e35bba5a23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame loaded from Excel file: Theatre_raw_SQL_data_TO_2018_2024.xlsx\n",
      "DataFrame saved as CSV: Theatre_data_prepared_TO_2018_2024.csv\n"
     ]
    }
   ],
   "source": [
    "#data_prep_first_step_after_SQl_extraction('Theatre_raw_SQL_data_TO_col_2018_2024.xlsx', 'Theatre_data_prepared_TO_col_2018_2024.csv')\n",
    "data_prep_first_step_after_SQl_extraction('Theatre_raw_SQL_data_TO_2018_2024.xlsx', 'Theatre_data_prepared_TO_2018_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd787f0-2227-41ef-b02d-22aa5f1461c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc48fc8-8674-4d2c-8aa9-162ec1e1a9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa6950-bdfc-49a1-ae01-29b730a603e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b3050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_values(df):\n",
    "    counts = []\n",
    "    for col in df.columns:\n",
    "        temp_name = df[col].value_counts().to_frame()\n",
    "        temp_name.name = col\n",
    "        counts.append(temp_name)\n",
    "        \n",
    "    return(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0843b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df['POSTCODE_LSOA'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4069b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = r'//esneft.nhs.uk/share/Finance/Capacity & Analytics/Business Informatics/Analytics Team/Health Inequalities/Reference Tables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4c146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dod = pd.read_csv(os.path.join(path2, \"DoD_LSOA.csv\"), encoding_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ee1e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "dod = dod[['LSOA code (2011)', 'Index of Multiple Deprivation (IMD) Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "           'Income Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "           'Employment Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "           'Education, Skills and Training Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "           'Health Deprivation and Disability Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "           'Crime Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "           'Barriers to Housing and Services Decile (where 1 is most deprived 10% of LSOAs)',\n",
    "          'Living Environment Decile (where 1 is most deprived 10% of LSOAs)' ]]\n",
    "\n",
    "dod = dod.rename(columns={'Index of Multiple Deprivation (IMD) Decile (where 1 is most deprived 10% of LSOAs)': 'Index of Multiple Deprivation Decile',\n",
    "           'Income Decile (where 1 is most deprived 10% of LSOAs)':  'Income Decile',\n",
    "           'Employment Decile (where 1 is most deprived 10% of LSOAs)' : 'Employment Decile',\n",
    "           'Education, Skills and Training Decile (where 1 is most deprived 10% of LSOAs)' : \"Education and Skills Decile\" ,\n",
    "           'Health Deprivation and Disability Decile (where 1 is most deprived 10% of LSOAs)' : 'Health and Disability Decile',\n",
    "           'Crime Decile (where 1 is most deprived 10% of LSOAs)' :  'Crime Decile',\n",
    "           'Barriers to Housing and Services Decile (where 1 is most deprived 10% of LSOAs)' : 'Barriers to Housing and Services Decile',\n",
    "          'Living Environment Decile (where 1 is most deprived 10% of LSOAs)' : 'Living Environment Decile'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28278cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dod, how='left', left_on='POSTCODE_LSOA', right_on='LSOA code (2011)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e0740-859b-46a3-a428-707850db5f2d",
   "metadata": {},
   "source": [
    "##### REPLACE MISSING VALUES WITH NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c79da61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_val = ['Unknown', '^Not Stated', 'Not Known']\n",
    "df = df.replace(missing_val, np.nan, regex=True)\n",
    "\n",
    "#missing = df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4d1db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae18f964",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df62d20-af94-4a96-a58f-feee2a42e9b3",
   "metadata": {},
   "source": [
    "##### COUNT NUMBER OF PROCEDURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab24b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#count number of non empty secondary procedure cells to get total of secondary procedures in each spell\n",
    "#df['N_Secondary_proc'] = df.iloc[:,78:127:2].apply(lambda x: x.count(), axis=1)\n",
    "\n",
    "def add_count_column(df1, columns_to_count, new_col):\n",
    "    # Calculate the count of non-missing and non-zero values for each row\n",
    "    df1[new_col] = df1[columns_to_count].apply(lambda row: (row != 0) & (pd.notna(row))).sum(axis=1)\n",
    "\n",
    "procedures_cols = ['Actual Procedure 1 Code 1',\n",
    "                      'Actual Procedure 2 Code 1',\n",
    "                      'Actual Procedure 3 Code 1']\n",
    "\n",
    "add_count_column(df, procedures_cols, 'N_procedures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0969eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[col for col in df.columns if 'anaes' in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3332234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "anaesthetic_cols = ['anaesthetist 1 Surname, Forename',\n",
    "                      'anaesthetist 2 Surname, Forename',\n",
    "                      'anaesthetist 3 Surname, Forename']\n",
    "\n",
    "add_count_column(df, anaesthetic_cols, 'Anaesthetist Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cbbd78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anaesthetist Count\n",
       "2    7606\n",
       "3    3789\n",
       "0    2364\n",
       "1     503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Anaesthetist Count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bfd3e49-7e95-496f-a7e2-b9281fca9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vals = unique_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6542adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vals = unique_values(df)\n",
    "\n",
    "#renaming ethnic groups to ensure consistency (e.g. difference in spelling)\n",
    "#groups renamed according to 2021 Census - 16 groups in total (with 3 groups not represented in this dataset)\n",
    "df = df.replace({'ETHNICITY': {'White - Any other White background' : 'Any other White background',\n",
    "                          'Any Other Ethnic Group': 'Any other ethnic group',\n",
    "                          'Black African or Black British African' : 'Black or Black British - African',\n",
    "                         'Any other Black background': 'Black or Black British - Any other Black background',\n",
    "                          'Black Caribbean or Black British Caribbean':'Black or Black British - Caribbean',\n",
    "                          'White - British': 'White British',\n",
    "                          'White - Irish' : 'White Irish',\n",
    "                          'Mixed - White and Asian':'Mixed White and Asian',\n",
    "                          'Mixed - White and Black Caribbean' : 'Mixed White and Black Caribbean',\n",
    "                          'Mixed - Any other background': 'Any other mixed background',\n",
    "                          'Mixed - White and Black African' : 'Mixed White and Black African',\n",
    "                          'Pakistani or British Pakistani': 'Asian or Asian British - Pakistani',\n",
    "                          'Other Ethnic Group - Chinese': 'Asian or Asian British - Chinese',\n",
    "                          'Chinese': 'Asian or Asian British - Chinese',\n",
    "                          'Bangladeshi or British Bangladeshi':'Asian or Asian British - Bangladeshi',\n",
    "                          'Asian - other' : 'Asian or Asian British - Any other Asian background',\n",
    "                          'Indian or British Indian':'Asian or Asian British - Indian'}})\n",
    "\n",
    "#df_etn_vals = unique_values(df)\n",
    "\n",
    "#create another variable with grouped ethnic categories, due to high imbalance in categories \n",
    "white = ['White British', 'White Irish', 'Any other White background']\n",
    "other_ethnic_group = ['Any other ethnic group',\n",
    "                      'Black or Black British - African',\n",
    "                      'Black or Black British - Any other Black background',\n",
    "                      'Black or Black British - Caribbean',\n",
    "                      'Mixed White and Asian',\n",
    "                      'Mixed White and Black Caribbean',\n",
    "                      'Any other mixed background',\n",
    "                      'Mixed White and Black African',\n",
    "                      'Asian or Asian British - Pakistani',\n",
    "                      'Asian or Asian British - Chinese',\n",
    "                      'Asian or Asian British - Chinese',\n",
    "                      'Asian or Asian British - Bangladeshi',\n",
    "                      'Asian or Asian British - Any other Asian background',\n",
    "                      'Any other Asian background',\n",
    "                      'Asian or Asian British - Indian']\n",
    "\n",
    "conditions = [df['ETHNICITY'].isin(white), df['ETHNICITY'].isin(other_ethnic_group),\n",
    "              df['ETHNICITY'].isna()]\n",
    "\n",
    "categories = ['Any white background', 'Any other ethnic background', \"None\"]\n",
    "\n",
    "df['Ethnicity_grouped'] = np.select(conditions, categories)\n",
    "\n",
    "#check_ethnicity = unique_values(df)\n",
    "\n",
    "no_missing = df.replace('None', np.nan)\n",
    "\n",
    "check_miss = no_missing.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ee9382-7930-4ca3-b145-b8cdb2ee1809",
   "metadata": {},
   "source": [
    "##### STRIP--AND--LOWER--CASE--PROCEDURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d1bb095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "procedure_1 = df.filter(like=\"Actual Procedure 1 Description\")\n",
    "procedure_2 = df.filter(like=\"Actual Procedure 2 Description\")\n",
    "procedure_3 = df.filter(like=\"Actual Procedure 3 Description\")\n",
    "\n",
    "def lower_case(df, cut):\n",
    "    for col in cut:\n",
    "        df[col] = df[col].str.lower()\n",
    "    return(df)\n",
    "\n",
    "df = lower_case(df, procedure_1)\n",
    "df = lower_case(df, procedure_2)\n",
    "df = lower_case(df, procedure_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685bfe2",
   "metadata": {},
   "source": [
    "### Adding the Scondary-diagnosis to the columns categorically by exploring into the secondary codes data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bda9a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "Codes_for_conditions = {\n",
    "    'IHD': ['I200', 'I201', 'I208', 'I209', 'I210', 'I211', 'I212', 'I213', 'I214', 'I219', 'I220', 'I221', 'I228', 'I229', \n",
    "            'I230', 'I231', 'I232', 'I233', 'I234', 'I235', 'I236', 'I238', 'I240', 'I241', 'I248', 'I249', 'I250', 'I251', 'I252', 'I253', 'I254', 'I255', 'I256', 'I258', 'I259'],\n",
    "    'PAD': ['I7021', 'I7020', 'I7081', 'I7080', 'I7091', 'I7090', 'I72', 'I730', 'I731', 'I738', \n",
    "            'I739', 'I742', 'I743', 'I744', 'I745', 'I748', 'I749', 'I77', 'I792', 'I798'],\n",
    "    'Myocardial infraction': ['I21', 'I22', 'I23', 'I252', 'I258'],\n",
    "    'Cerebral vascular': ['G450', 'G451', 'G452', 'G454', 'G458', 'G459', 'G46', 'I60',\n",
    "                          'I61', 'I62', 'I63', 'I64', 'I65', 'I66', 'I67', 'I68', 'I69'],\n",
    "    'Congestive heart failure': ['I500'],\n",
    "    'Connective tissue disorder': ['M05', 'M060', 'M063', 'M069', 'M32', 'M332', 'M34', 'M353'],\n",
    "    'Dementia': ['F00', 'F01', 'F02', 'F03', 'F051'],\n",
    "    'Hypertension': ['I10', 'I11', 'I12', 'I13', 'I15', 'I16'],\n",
    "    'Diabetes': ['E101', 'E105', 'E106', 'E108', 'E109', 'E111', 'E115', 'E116', 'E118', 'E119', 'E131', 'E135', 'E136', 'E138', 'E139', 'E141', 'E145', 'E146', 'E148', 'E149'],\n",
    "    'Liver disease': ['K702', 'K703', 'K717', 'K73', 'K74'],\n",
    "    'Obesity': ['Z68', 'E66'],\n",
    "    'Peptic ulcer': ['K25', 'K26', 'K27', 'K28'],\n",
    "    'Periph vasc disease': ['I71', 'I739', 'I790', 'R02', 'Z958', 'Z959']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0341e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_code_cols = df.columns[df.columns.str.startswith('Secondary_Diagnosis')][0:-1:2]\n",
    "#secondary_code_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "302942dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[Codes_for_conditions.keys()] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d280dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the rows and columns to check for the presence of strings\n",
    "for key, string_list in Codes_for_conditions.items():\n",
    "    #print(string_list)\n",
    "    #default value is 0\n",
    "    diagnosis_result = np.zeros(len(df))\n",
    "    for index, row in df.iterrows():\n",
    "        for diag_code in row[secondary_code_cols]:  # Exclude the last column (NewColumn)\n",
    "            if pd.isna(diag_code):\n",
    "                break\n",
    "            if any(s in diag_code for s in string_list):\n",
    "                diagnosis_result[index]= 1\n",
    "                break  # Stop checking if a string is found in any column\n",
    "    df[key] = diagnosis_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0770d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Obesity'].value_counts()\n",
    "#df.to_csv('Latest_Theatre_data_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42b633d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actual Procedure 1 Code 1\n",
       "W409    1475\n",
       "W903     959\n",
       "W879     862\n",
       "W283     676\n",
       "W379     612\n",
       "        ... \n",
       "T625       1\n",
       "W596       1\n",
       "W931       1\n",
       "W514       1\n",
       "S575       1\n",
       "Name: count, Length: 340, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Actual Procedure 1 Code 1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89e1f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Primary Procedure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8125d8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System Key</th>\n",
       "      <th>FACT_IP_SPELLS_ID</th>\n",
       "      <th>System Name</th>\n",
       "      <th>Hosp</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>AGE_ON_ADMISSION</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>Gender</th>\n",
       "      <th>POSTCODE_LSOA</th>\n",
       "      <th>postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Peptic ulcer</th>\n",
       "      <th>Periph vasc disease</th>\n",
       "      <th>Pulmonary Disease</th>\n",
       "      <th>Diabetes compl</th>\n",
       "      <th>Paraplegia</th>\n",
       "      <th>Renal disease</th>\n",
       "      <th>Metastatic</th>\n",
       "      <th>Severe liver</th>\n",
       "      <th>HIV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>11950161</td>\n",
       "      <td>Medway</td>\n",
       "      <td>COL</td>\n",
       "      <td>D0305927</td>\n",
       "      <td>66</td>\n",
       "      <td>White British</td>\n",
       "      <td>Female</td>\n",
       "      <td>E01021993</td>\n",
       "      <td>CO7 8NX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>11950149</td>\n",
       "      <td>Medway</td>\n",
       "      <td>COL</td>\n",
       "      <td>D0629159</td>\n",
       "      <td>54</td>\n",
       "      <td>White British</td>\n",
       "      <td>Male</td>\n",
       "      <td>E01021715</td>\n",
       "      <td>CO2 9HB</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>11950148</td>\n",
       "      <td>Medway</td>\n",
       "      <td>COL</td>\n",
       "      <td>D0862257</td>\n",
       "      <td>35</td>\n",
       "      <td>White British</td>\n",
       "      <td>Male</td>\n",
       "      <td>E01021699</td>\n",
       "      <td>CO4 3RH</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>11950163</td>\n",
       "      <td>Medway</td>\n",
       "      <td>COL</td>\n",
       "      <td>D2016276</td>\n",
       "      <td>56</td>\n",
       "      <td>White British</td>\n",
       "      <td>Female</td>\n",
       "      <td>E01021715</td>\n",
       "      <td>CO2 9RJ</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>11950146</td>\n",
       "      <td>Medway</td>\n",
       "      <td>COL</td>\n",
       "      <td>D6069894</td>\n",
       "      <td>35</td>\n",
       "      <td>White British</td>\n",
       "      <td>Male</td>\n",
       "      <td>E01021677</td>\n",
       "      <td>CO6 1XS</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   System Key  FACT_IP_SPELLS_ID System Name Hosp Patient ID  \\\n",
       "0        1000           11950161      Medway  COL   D0305927   \n",
       "1        1000           11950149      Medway  COL   D0629159   \n",
       "2        1000           11950148      Medway  COL   D0862257   \n",
       "3        1000           11950163      Medway  COL   D2016276   \n",
       "4        1000           11950146      Medway  COL   D6069894   \n",
       "\n",
       "   AGE_ON_ADMISSION      ETHNICITY  Gender POSTCODE_LSOA postcode  ...  \\\n",
       "0                66  White British  Female     E01021993  CO7 8NX  ...   \n",
       "1                54  White British    Male     E01021715  CO2 9HB  ...   \n",
       "2                35  White British    Male     E01021699  CO4 3RH  ...   \n",
       "3                56  White British  Female     E01021715  CO2 9RJ  ...   \n",
       "4                35  White British    Male     E01021677  CO6 1XS  ...   \n",
       "\n",
       "  Obesity Peptic ulcer Periph vasc disease  Pulmonary Disease Diabetes compl  \\\n",
       "0     0.0          0.0                  0.0               1.0            0.0   \n",
       "1     0.0          0.0                  0.0               0.0            0.0   \n",
       "2     0.0          0.0                  0.0               1.0            0.0   \n",
       "3     0.0          0.0                  0.0               0.0            0.0   \n",
       "4     0.0          0.0                  0.0               0.0            0.0   \n",
       "\n",
       "  Paraplegia Renal disease Metastatic Severe liver  HIV  \n",
       "0        0.0           0.0        0.0          0.0  0.0  \n",
       "1        0.0           0.0        0.0          0.0  0.0  \n",
       "2        0.0           0.0        0.0          0.0  0.0  \n",
       "3        0.0           0.0        0.0          0.0  0.0  \n",
       "4        0.0           0.0        0.0          0.0  0.0  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e657aeb6-af03-4e0e-a743-5798c2bb0e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14262"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5962591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_to_group(age, cutoffs = None):\n",
    "    if cutoffs is None:\n",
    "        cutoffs = [5, 15, 30, 50, 60, 70, 80]\n",
    "    for i, cutoff in enumerate(cutoffs):\n",
    "        if age <= cutoff:\n",
    "            if i == 0:\n",
    "                return f\"0to{cutoff}\"\n",
    "            elif i == len(cutoffs) - 1:\n",
    "                return f\"{cutoffs[i-1]+1}to{cutoff}\"\n",
    "            else:\n",
    "                return f\"{cutoffs[i-1]+1}to{cutoff}\"\n",
    "    return f\"Above{cutoffs[-1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6861459",
   "metadata": {},
   "source": [
    "#### Adding extra column with age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5659f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cutoffs = [5, 15, 30, 50, 60, 70, 80]\n",
    "df['Age group at admit'] = df['AGE_ON_ADMISSION'].apply(lambda x: age_to_group(x, custom_cutoffs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ba165",
   "metadata": {},
   "source": [
    "#### Filling up out of theatre time if missing to calculate post-op LOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b20d6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Arrived Date/Time'] = pd.to_datetime(df['Arrived Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "df['Out of Theatre Date/Time'] = pd.to_datetime(df['Out of Theatre Date/Time'], format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "df['Out of Theatre Date/Time'] = df.apply(lambda row: row['Arrived Date/Time'] + pd.to_timedelta(row['H4 Minutes'], unit='minutes')\n",
    "                               if pd.isnull(row['Out of Theatre Date/Time']) else row['Out of Theatre Date/Time'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02f603",
   "metadata": {},
   "source": [
    "#### Adding Actual LOS and Post-op LOS columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b54ffbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Actual LOS'] = (pd.to_datetime(df['Discharge Date/Time'],format=\"%d/%m/%Y %H:%M\") - pd.to_datetime(df['Admission Date/Time'],format=\"%d/%m/%Y %H:%M\")).dt.total_seconds() / (24 * 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "edc1770e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Post-Op LOS'] = (pd.to_datetime(df['Discharge Date/Time'],format=\"%d/%m/%Y %H:%M\") - pd.to_datetime(df['Out of Theatre Date/Time'],format=\"%d/%m/%Y %H:%M\")).dt.total_seconds() / (24 * 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116b4bc",
   "metadata": {},
   "source": [
    "#### Adding Day of the week and Month columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46d10e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Admission Date/Time'] = pd.to_datetime(df['Admission Date/Time'],format=\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "df['Month'] = df['Admission Date/Time'].apply(lambda x: x.strftime('%B'))\n",
    "df['Day of the week'] = pd.to_datetime(df[\"Planned Start Date/Time\"],format=\"%d/%m/%Y %H:%M\").dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972f240",
   "metadata": {},
   "source": [
    "#### Adding Covid-Flag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75c46187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise_covid_period(date):\n",
    "    if date < pd.Timestamp('2020-03-01'):\n",
    "        return 'pre-covid'\n",
    "    elif date >= pd.Timestamp('2020-03-01') and date <= pd.Timestamp('2021-03-30'):\n",
    "        return 'covid'\n",
    "    else:\n",
    "        return 'post-covid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c283a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Covid Flag'] = df['Admission Date/Time'].apply(categorise_covid_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdecfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9df98c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "theatre_with_laminar_flow = ['Theatre 10', 'Theatre 11', 'Theatre 15']\n",
    "df['Theatre Airflow System'] = df['Theatre Name'].apply(lambda x: 'Laminar' if x in theatre_with_laminar_flow else 'Non laminar')\n",
    "df['Theatre category1'] = df['Theatre Suite Name'].apply(lambda x: 'daycase patients' if x == 'Elmstead Theatres' else 'mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc24246a",
   "metadata": {},
   "source": [
    "#### Exporting to the csv format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a730e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Theatre_data_2018_2024.csv')\n",
    "#df.to_csv('InPatient_flow_data_inc_diag_encoded_Jun_Aug_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a556e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hosp\n",
       "COL    11865\n",
       "IPS     7141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Hosp'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6055fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Actual Procedure 1 Code 1.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3dcb8478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Connective tissue disorder', 'Dementia', 'Hypertenstion', 'Diabetes',\n",
       "       'Liver disease', 'Peptic ulcer', 'Periph vasc disease ',\n",
       "       'Pulmanory disease', 'Diabetes compl', 'Paraplegia', 'Renal disease',\n",
       "       'Metastatic', 'Severe liver', 'HIV', 'Age group at admit', 'Actual LOS',\n",
       "       'Post-Op LOS', 'Month', 'Day of the week', 'Covid Flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[-20:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
